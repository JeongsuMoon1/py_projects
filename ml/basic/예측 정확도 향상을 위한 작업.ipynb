{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 알고리즘 적용 후 결과 반영 \n",
    "\n",
    "- 이미 전처리된 데이터들을 끌어다가 쓸 것이다.( 예) 유방암 데이터 )\n",
    "- load_breast_cancer() 분류용 유방암 진단 데이터 세트\n",
    "- 1~4단계 모드 생략, 바로 5단계 진입\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모듈가져오기, 알고리즘 및 기타 성능관련 모듈\n",
    "from sklearn.svm import SVC   # SVM : 성능적으로 가장 유사하여 계속 쓰는 중\n",
    "from sklearn.datasets import load_breast_cancer # 유방암 데이터 가져오기\n",
    "from sklearn.model_selection import train_test_split # train_test_split : 훈련용과 테스트용 데이터를 나눠준다(섞어서 빼준다)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 로드 및 분류 (훈련용, 테스트용)\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터는 569개 , 유방암을 진단하는 항목(특성, 변수, feature, 컬럼) 30개가 존재함\n",
    "cancer['data'].shape # 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569,), array(['malignant', 'benign'], dtype='<U9'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# malignant : 악성\n",
    "# benign    : 양성\n",
    "# 답이 2개  : 값을 나누기 위한 변수 형태 => 분류 변수 => 종류가 2개 => 이진데이터 => 0 혹은 1 (0 or 1), 0 이 악성인 1 이 악성인지 봐야한다\n",
    "cancer['target'].shape, cancer['target_names'] # 종속변수 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답( 양성이냐 악성이냐)을 어떻게 표현하는지 샘플링을 한 것이다\n",
    "cancer['target'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유방암을 진단하는 30개 항목 이름\n",
    "cancer['feature_names'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분류 작업\n",
    "# 머신러닝에서는 대문자를 쓰는 관습적인 경향이 있다\n",
    "# random_state=() : 데이터는 섞는(셔플) 난수의 시드값(설정값)\n",
    "# test_size : 테스트 데이터의 비율 \n",
    "X_train, X_test, y_train, y_test = train_test_split( cancer.data, # 데이터 : 독립\n",
    "                                                   cancer.target, # 답: 종속\n",
    "                                                   random_state=0,\n",
    "                                                    test_size=0.25 # 25% \n",
    "                                                   )  # X_train(데이터, 독립변수), X_test(독립변수), y_train(답, 종속), y_test(종속)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30), (426,), (143,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(y_train) # 배열로 뽑힌다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에까지가 데이터의 특성등을 확인하는 과정이었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 알고리즘 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6293706293706294\n"
     ]
    }
   ],
   "source": [
    "print( svm.score(X_test, y_test ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svm.predict( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6293706293706294\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "ac_score = metrics.accuracy_score( y_test, predict ) # 답을 넣는다\n",
    "print(ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  데이터 전처리기를 적용해서 학습 후 결과 반영\n",
    "\n",
    "- 데이터 자체를 훈련하기 전에, 스케일링 작업을 수행하여 학습을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.185e+01, 1.746e+01, 7.554e+01, 4.327e+02, 8.372e-02, 5.642e-02,\n",
       "        2.688e-02, 2.280e-02, 1.875e-01, 5.715e-02, 2.070e-01, 1.238e+00,\n",
       "        1.234e+00, 1.388e+01, 7.595e-03, 1.500e-02, 1.412e-02, 8.578e-03,\n",
       "        1.792e-02, 1.784e-03, 1.306e+01, 2.575e+01, 8.435e+01, 5.178e+02,\n",
       "        1.369e-01, 1.758e-01, 1.316e-01, 9.140e-02, 3.101e-01, 7.007e-02]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1] # 데이터를 전처리 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 해야하는 데이터를 넣어서 스케일러 생성\n",
    "scaler = MinMaxScaler().fit( X_train ) # X_train을 이용해서 최소값 최대값을 가지고 온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler # 최대값을 1로, 최소값을 0으로 두고 그 사이를 쭉 나열시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform( X_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23044157, 0.32157676, 0.21940433, 0.12267232, 0.33767785,\n",
       "        0.12684063, 0.06298032, 0.11332008, 0.41161616, 0.15143218,\n",
       "        0.03458265, 0.19353412, 0.02247562, 0.0124343 , 0.27210066,\n",
       "        0.12240273, 0.03565657, 0.1624929 , 0.18735302, 0.03072012,\n",
       "        0.18249733, 0.36593817, 0.16903232, 0.081744  , 0.43406194,\n",
       "        0.14408515, 0.10511182, 0.31484671, 0.30277942, 0.09858323]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:1] # 0~1사이로 데이터가 들어온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit( X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "print( svm.score( scaler.transform(X_test), y_test ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍박스 doc에 매개변수 파일있는거 확인 후 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 튜닝 후 결과 반영\n",
    "\n",
    "- 머신러닝의 모형이 완성되고 난 이후, 매개변수 최적화를 통해 예측 성능을 더 극대화\n",
    "- 도구\n",
    " > validation_curve : 단일 하이퍼파라미터 최적화 도구   \n",
    " > GridSearchCV     : 그리드를 이용한 복수 하이퍼파라미터 최적화  \n",
    " > ParameterGrid    : 복수 하이퍼파라미터 최적화  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**알고리즘별 매개변수 목록**\n",
    "\n",
    "<img src='../doc/매개변수.png' width='50%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘에 대한 파라미터 구성\n",
    "# 여기서는 알고리즘을 SVM 계열 사용\n",
    "# 수치는 범위내 임의로 입력, 단 최저값은 추천 데드라인보다 더 내려서 입력\n",
    "param_grid = {\n",
    "    'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'gamma':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 적용\n",
    "# cv= : 교차 검증수( 폴드(fold), None, 3, 5, )\n",
    "# 5 fold => 데이터의 총개수를 5세트로 구성한다 \n",
    "grid = GridSearchCV( SVC(), param_grid=param_grid, cv=5 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 \n",
    "# 5fold 중에 4폴드는 훈련용, 1폴드는 검증용으로 사용 \n",
    "grid.fit( X_train_scaled, y_train ) # 그리드가 교차학습을 해야한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812206572769953"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_ # C:1, gamma:1 이 배스트이다\n",
    "# SVC( C=1, gamma=1 ) 이렇게 알고리즘을 생성하는 것이 최상의 결과치를 가져온다\n",
    "# 현 데이터 기준에서이다. (데이터가 바뀌면 당연히 바뀐다 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(scaler.transform(X_test), y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 현재 구성한 방식은 전처리 후 교차검증을 수행해서 최적 파라미터를 찾아냈다\n",
    "- 문제는, 순서상 전처리가 먼저되서 교차 검증 시 훈련용 데이터의 일부가 검증에 들어가는 문제가 들어간다 => 해결법 : 교차 검증 수행 후 전처리를 수행하는 시퀀스를 맞춰야 하는데 이를 구성하기 가장 좋은 방식은 파이프라인 구축이라는 방식을 활용\n",
    "\n",
    "- 스케일일 한 데이터를 가지고 교차 검증을 수행하면, 스케일러 데이터 안에 예측대상 폴드(데이트세트)가 구성되어 있어서, 신규 데이터 예측시 불확실하게 처리가 된다. 이를 방지하기 위해서 전처리 전에 교차 검증이 이루어져야 한다. => pipeline 구축을 통해 학습 모델과 전처리 단계를 연결하는 구성을 만들어야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|현재|개선(파이프라인이용)|\n",
    "|:---|---:|\n",
    "|<img src='../doc/cro.png'>|<img src='../doc/cro2.png'>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 인터페이스 적용 후 결과 반영\n",
    "\n",
    "- 전처리기 이외에 다른 알고리즘, 처리기와 연결\n",
    "- 특성 추출, 특성 선택, 스케일 변경, 분류(회귀 or 군집)등 4개를 포괄하는 파이프라인을 구축할 수 있다\n",
    "- 모든 추정기들은 transform() 함수들을 모두 다 가지고 있어서 언제든지 다음 단계로 연결시킬 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline # Pipeline로 클래스를 작성할 수 있다\n",
    "from sklearn.ensemble import RandomForestClassifier  # 분류기 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 분류 비율이 75:25 비율을 가진다 \n",
    "X_train, X_test, y_train, y_test = train_test_split( cancer.data, # 데이터 : 독립\n",
    "                                                     cancer.target, # 답: 종속\n",
    "                                                     random_state=0\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 구축\n",
    "# case 1 : 표준방법 -> 전처리기, 알고리즘등, 처리기에 이름 부여\n",
    "pipe_std    = Pipeline( [ ('scaler',MinMaxScaler()), ('classifier',SVC()) ] )\n",
    "# case 2 : 간소화 방법 -> 이름을 알아서 설정된다\n",
    "pipe_simple = make_pipeline( MinMaxScaler(), SVC() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scaler', MinMaxScaler(copy=True, feature_range=(0, 1)))\n",
      "('classifier', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 확인\n",
    "for pipe in pipe_std.steps:\n",
    "    print( pipe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))\n",
      "('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n"
     ]
    }
   ],
   "source": [
    "for pipe in pipe_simple.steps: # 이름을 자동 생성해줌 minmaxscaler 라고 생성됨\n",
    "    print( pipe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 데이터를 적용할 실 파이프\n",
    "pipe = Pipeline( [ \n",
    "                   ( 'preprocessing', StandardScaler() ), \n",
    "                   ( 'classifier', SVC() ) \n",
    "                  ] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier':[SVC()],\n",
    "        'preprocessing':[StandardScaler(), MinMaxScaler()],\n",
    "        # 매개변수가 동일명을 사용할 경우 구분\n",
    "        # 알고리즘별칭__매개변수명\n",
    "        'classifier__gamma':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__C':[0.001, 0.01, 0.1, 1, 10, 100]\n",
    "     },\n",
    "    {\n",
    "        'classifier':[RandomForestClassifier(n_estimators=100)], # 둘 중에 하나 써서 좋은걸 쓴다(svc냐 randomforest냐)\n",
    "        # 전처리기가 필요 없다\n",
    "        'preprocessing':[None],\n",
    "        'classifier__max_features':[1, 2, 3]\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'classifier': [SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)], 'preprocessing': [StandardScaler(copy=True, with...=0,\n",
       "            warm_start=False)], 'preprocessing': [None], 'classifier__max_features': [1, 2, 3]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit( X_train, y_train ) # 원 데이터가 들어간다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 0.01,\n",
       " 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_ # 랜덤포레스트보다 SVC가 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859154929577465"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score( X_test, y_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['classifier', 'classifier__C', 'classifier__gamma', 'preprocessing'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_.keys() # 세팅된 항목들 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능평가에 대한 항목을 본다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
