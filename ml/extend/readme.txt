1. 연구 목표
    - MovieLens(무비렌즈), 영화 평점 데이터
    - 사용자의 별점수를 예측
    - 개요
        > 2006년도 넷플릭스의 프라이스 경진 대회가 가장 유명
        > 추천 정확도를 기존 대비 10% 향상을 목표 -> 모토 : "모든 것이 추천이다" 슬로건을 가지고 진행
          https://medium.com/@NetflixTechBlog/55838468f429
        > 무비렌즈 데이터는 미네소타에서 제공, 넷플릭스와 비슷한 정보를 기반으로 연구용으로 공개한 데이터


2. 시스템 정의
    - 추천 시스템
        > 목적 : 어떤 사용자 행동이나 아이템에 대한 정보로부터, 사용자가 선호할만한 관련 아이템을 제시하는것
        > 특징 : 검색만으로는 사용자가 원하는 콘텐츠를 찾기가 어려운 경우(동영상/음악 스트리밍, 쇼핑몰) - 이런 곳에서 추천시스템이 필요하다
                 추천을 통해서 자신이 선호하는 콘텐츠를 발견하도록 도움을 주는 시스템
                 => 서비스 제공자들도 상품 구매 전환율을 높이거나, 활성 사용자수를 늘리는 기회로 사용
    - 응용 분야
        > 개요 추천 :
            1) 금주의 인기 상품 -> 통계 활용, 편집자 선택 아이템들을 추천 
            2) 개인화가 되어 있지 않는 추천 -> 시스템을 처음 이용하는 사용자, 가끔 이용하는 사용자 적합
        > 사용자 평가 :
            1) 다른 사람의 추천 -> 그 아이템의 신뢰를 줄 수 있는 근거가 된다 -> 사용자는 스스로 납득을 하고 선택을 할 수 있게 하는 방향으로 전개
            2) 다른 사용자의 별점, 댓글을 보여주거나, 평균 평점 노출
        > 알림 서비스
            1) 푸시 / 이메일등을 통해 사용자가 흥미를 느낄 아이템을 추천 혹은 사이트 재방문 유도
        > 연관 아이템 추천
            1) 원래 아이템과 함께 연관된 아이템을, 그 정보를 제시하여 동시 구매를 유도
            2) 다른 아이템과 비교하게 함
            3) 전자 상거래의 정석
        > 개인화
            1) 인기 아이템 목록 / 편집자 추천 목록 => 사용자가 흥미를 느끼는 아이템을 노출, 사용자 마음에 드는 아이템을 찾도록 도움을 주는 시스템
            2) 검색 결과도 개인화를 적용


3. 데이터 설계 / 획득
    - 선호 데이터 
        > 사용자가 특정 아이템을 얼마나 선호하는가?
    - 검색 쿼리
        > "7,000원이하 햄버거집" 검색
    - 비평, 후기
        > 상품에 대한 업체에 대한 댓글평, 
    - 아이템 특징
        > 상품 설명에 쓰인 단어등에 대한 정보
    - 인구적 특징
        > 사용자의 연령, 성별
    - 맥락적 특징
        > 추천받은 아이템을 사용한 날짜, 위치 정보, 재고 현황, 이런 데이터를 통한 맥락적, 연관적 정보
    


4. 영화 추천 기준 평가 데이터 관련
    - 데이터가 매우 희소하다, 많이 없다. 오래된 영화일수록 평가가 더 많다라는 문제 내포 => 추천 시스템의 구축이 어렵다(옛날 정보이기 때문에)
    - 기준 평가
        > 사람마다 지금까지(현재시점) 본 영화가 모두 다르다
        > 인기 영화는 평가 정보가 많다. 아닌 영화는 정보가 적다 => 추천이 안된다
        > 영화는 한해에 엄청나게 쏟아지는데, 한 사용자는 평생 볼 수 있는 영화수가 많지 않다. (상대적) 
        > 평가 정보가 특정 아이템에 몰리게 될 수 있고, 평점 행렬의 요소 대부분이 값을 가지지 않게 된다.
          => 결측치가 많다
        > 평점 행렬 : 각 사용자가 각 영화(아이템)에 대해 평점을 기재한 데이터 : 2차 행렬
                      
                      영화1  영화2  영화3
        -----------------------------------    => 이렇게 비어있는 공간이 많다
        사용자1          5             1
        사용자2          4             2
        사용자3                 3      3 
        
        > 선호 데이터 => 평가 정보 => 정답 데이터로 활용이 가능
        > 아이템의 평가 비용 ( 음악은 1곡을 듣고 평가를 수행할 수 있다 => 3~5분 => 상대적으로 선호 데이터를 구하기 쉽다 )
        > 주택 구입, 결혼식 예식장 선정 등등 = 시간이 많이 소요 => 선호 데이터가 입수가 쉽지 않다 => 간접 지표를 통해서 선호데이터를 보충
          (페이지 노출, 클릭, 머문시간 등등)

5. 선호 데이터 수집 방법 : 명시적 데이터 / 묵시적 데이터
    - 명시적 데이터
        > 사용자에게 직접, 선호도를 물어서 답변을 구하는 방식
    - 묵시적 데이터
        > 상품을 구매하거나, 상품 정보를 열람( 기웃기웃 거린다 ) => 이 아이템에 흥미를 가지고 있다 => 이런 데이터를 모으는 방법
        
                                         명시적         묵시적
        -----------------------------------------------------------
        데이터양                           X               O
        데이터의 정확성                    O               X             
        미평가와 부정적 평가 구분          O               X
        사용자의 인지성                    O               X



6. 추천 시스템 알고리즘
    - 협업 필터링 : collaborative filtering
        > 메모리 기반 협업 필터링 : memory-based collaborative filtering
        
            1) 사용자 기반 협업 필터링 : user-based collaborative filtering -> 당신과 비슷한 상품을 산 고객은 이런 상품도 샀다
                a. 피어슨 상관관계, 코사인 유도, 자카드 계수 등 등장 
            
            2) 아이템 기반 협업 필터링 : item-based collaborative filtering -> 방금 막 가입한 사용자에게 적용하기에 적합하다
        
        > 모델 기반 협업 필터링 : model-based collaborative filtering -> 회귀/분류등 예측 모델을 학습해서 처리
    
    - 내용 기반 필터링 : content-based filtering -> 영화라면 메타정보(제목, 감독, 장르, 배우, 평판 등등 간접지표를 통해 나타나는 정보에 주목)

7. 사용자 기반 협업 필터링
    [나와 비슷한 사용자는 어떻게 찾을 것인가? => 여러개의 요소중에 평점을 기준으로 하겠다 => 평점행렬을 구성 => 유사도를 측정 
        => 그 기반 기술( 피어슨 상관관계, 코사인 유도, 자카드 계수)가 있다]
        
    - 당신과 비슷한 상품을 산 고객은 이런 상품도 샀다
    
    - 사용자와 아이템의 쌍에 대한 평점 행렬이 있는 경우, 이런 행렬에 누락된 요소(모든 고객이 영화를 볼 수 없기 때문에)에 해당하는 평점을 예측
        > 사용자 정보를 백터로 표현
        > 사용자간의 유사도를 평가( 당신과 비슷한 상품을 산 고객과의 구별을 유사도를 가지고 측정 )            
    
    - 방식(3가지) 
        > (설명) 평점 행렬 => rating[사용자별 영화별 평가 점수 인덱스][영화별 인덱스]
                 i번째 사용자(u = user[i]) U의 평점백터 u = [rating[i][0], rating[i][3], rating[i][m]] # i: 사용자, m: 사용자가 찍은 평점 i번째 m번
                 j번째 사용자(u = user[j]) U의 평점백터 u = [rating[j][0], rating[j][3], rating[j][m]]
                 ==> 유사도값 : 대상이 비슷하면 값이 커지고, 다르면 작아지는 척도(기준 지표)
        
        [numpy 직접구현(row레벨적임), scipy 함수로 지원(상위레벨적임)]
        > 피어슨 상관관계
            1) 가장 일반적인 상관 계수
             [numpy]
                import numpy as np
                def person_coefficient_law(u, v):
                    u_diff = u - np.mean(u)
                    v_diff = v - np.mean(v)
                    # dot : 내적, 외적에 대한것이 떠올려야 한다, ** : 제곱
                    return np.dot(u_diff, v_diff) / (np.sqrt(sum(u_diff ** 2)) * np.sqrt(sum(v_diff ** 2)))
                
             [scipy]
                from scipy.spatial.distance import correlation
                def person_coefficient(u, v):
                    return 1 - correlation(u, v)
                
        > 코사인 유도
            1) 텍스트 문장 간의 거리를 측정하는 척도용
                # 코사인 유도
                from scipy.spatial.distance import cosine
                def cosine_similarity( u, v ):
                    return 1 - cosine( u, v)
                    
                # 코사인 유도 직접 구현
                import numpy as np
                def cosine_similarity_law( u, v ):
                    return np.dot( u, v ) / ( np.sqrt( sum( u ** 2 ) ) * np.sqrt( sum( v ** 2) ) )
            
        > 자카드 계수
            1) 집합과 집합 사이의 거리를 계산, 0~1으로만 구성된다
                from scipy.spatial.distance import jaccard
                def jaccard_similarity( u, v ):
                    return 1- jaccard(u, v)

                # 자카드 계수 직접 구현
                import numpy as np
                def jaccard_similarity( u, v ):
                    return np.dot( u, v ) / ( sum(np.absolute(u)) + sum(np.absolute(v)) - np.dot(u,v)  )



8. 아이템 기반 협업 필터링
    - 방금 막 가입한 사용자에게 적용하기에 적합
    - 활동이 아주 저조한 유저에게도 적용하기에 적합
    - 단, 예상되는 문제점은 인기 아이템만 노출이 집중되는 문제가 있어서, 이외의 아이템들을 노출하는 보강 작업이 필요로 하다
    - 사용자 기반 협업 필터링과 유사점이 있고, 코사인 유도를 개선된 방식으로 사용
        adjusted cosine similarity: 개선된 코사인 유도
    - 영화 평점 M의 평점 백터를 m
      영화 N의 평점 백터를 n
      사용자 평균 평점 u_mean
      ----------------------------------
      [numpy에서 구현]
       # 개선된 코사인 유도 
       import numpy as np
       def adjusted_cosine_similarity( m, n, u_mean ):
            ad_m = m - u_mean
            ad_n = n - u_mean
            return np.dot( ad_m, ad_n ) / ( np.sqrt( sum( ad_m ** 2 ) ) * np.sqrt( sum( ad_n ** 2) ) )
      

9. 모델 기반 협업 필터링
    - 회귀/분류등 에측 모델을 학습해서 처리 => 지도/비지도 학습방법을 이용하여 기존 데이터가 가지는 규칙성에 따라 예측 및 추천하는 방법
    - 방법적 예
        > 군집화를 사용하는 모델 : 비지도 학습(이라고 한다)
            1) 선호도가 비슷한 사용자들을 그룹을 묶고, 특정 사용자가 자신이 속한 그룹이 선호하는 아이템을 추천
            
        > 평점에 대한 회귀 모델
            1) 선형 회귀
            2) 모델 학습후 평점을 예측(나이, 평점, 흥미 등등을 또 분류하여 예측)
            3) 이 평점 기준으로 그 점수에 도달해있는 작품들을 추천(방법론은 좀더 확장)
        
        > 토픽을 이용한 모델
            1) 멜로 장르 선호, sf 장르 선호등 잠재적인 의미를 드러내는 기법
            2) 묵시적 데이터로 획득 가능
            3) 방법
                a. 확률적 잠재 의미 분석 : PLSA
                b. 잠재 디리클레 할당    : LDA
            
        
        > 행렬분해 (행렬 인수분해 -> fastFM, libFM 이 이런 기능을 지원)
            1) 차주 진행 예정
            2) 코드예에서 사용

10. 내용 기반 필터링
    - 영화라면 메타정보(제목, 감독, 장르, 배우, 평판 등등 간접지표를 통해 나타나는 정보에 주목)
    - 이런 정보들의 과거 정보들 이용하여 추천 항목 구성/선택
    - 이런 정보속에 사용자의 취향을 표출하는 단어를 알 수 있다면(발견되면) 그 정보를 통해서 취향에 맞는 영화들을 제시할 수 있다(그에 알맞는 데이터 필요)

11. 비교 ( 협업 필터링 <-> 내용 기반 필터링 )
    - 협업 필터링
        > 장르, 텍스트 등에 포함된 단어에 유사점이 없어도, 다양한 추천 결과를 얻을 수 있는 가능성이 크다.
        > 도메인에 대한 지식, 관리할 필요도 없다
        > 문제점 : 데이터가 충분히 쌓이기 전까지 -> 신규 사용자에게 새로운 아이템 추천 불가
                   -> 콜드 스사트 문제
                   -> 사용자가 적으면 준비된 추천 알고리즘을 적용한 추천이 자체가 불가능하고 => 사용자가 늘지 않고 
                       => 데이터가 없고 => 추천이 불가능한 악순환에 빠질 수 있다 => 초반 전략과, 데이터가 확보된 이후 전략을 달리하거나 적적히 섞어서구현
        > 아이템 기반 협업 필터링같은 방식을 이용하여 누적 행동 데이터등 누적 데이터가 없는 상황에서도 적절한 추천을 수행할수 있다
    
    - 내용 기반 필터링
        > 아이템의 내용을 기초로 누적 행동 데이터가 없어도 적절한 추천이 가능
        > 한국어 => 형태소 분석, 유지 보수 측면 등등 도메인에 특화된 이슈들이 제법 존재한다
        
    

12. 평가 척도
    - 분류 방식의 평가
        > 정확도 : accurancy
            1) 5단계 평점에서 4점 이상 받으면 정답으로 간주 => label화
            2) 예측결과와 사용자의 평점을 비교
            3) 정밀도 : precision -> 예측 결과 중 실제 접당의 비율 
            4) 재현율 : recall    -> 전체 정답 중 정답을 맞춘 비율
    
    - 회귀 방식의 평가
        > 회귀로 예측한 별점의 개수등 이런 형태로 추천을 사용.
        > RMSE : 평균 제곱근 오차 : Root mean squared error
            1) 예측값과 실제값의 차이를 제곱한 값
            2) 오차가 클수록 평균제곱근값도 커진다. -> 작을수록 정확해지는 특성
            3) MAE 대비 이상값에 취약한 단점을 가지고 있다.
        > MAE  : 평군 절대 오차   : Mean absolute error
            1) 예측값과 실제값의 차이에 대한 절대값으로부터 평점을 계산
            2) 예측값과 실제값의 오차가 클수록 평균 절대 오차도 커진다.
            
    - 순위상관
        > 추천한 아이템의 순서를 평가하는 지표 -> 랭킹학습
    
    - 커버리지
        > 다양성을 평가 지표에 포함시켜, 전체 아이템 중에서 평점을 예측할 수 있는 아이템의 비율로 평가를 수행
    
13. 분석 및 데이터 획득
    - 목표
        > 무비렌즈 데이터를 이용하여 추천 시스템을 구축한다 -> 상황인지추천
        > 상황인지추천 : 사용자(나이, 성별 등등)와 아이템 정보외의 정보를 활용하여 추천하는 방식
    - 데이터 획득
        > wget http://files.grouplens.org/papers/ml-100k.zip  -> 파일을 받는다!!
            [압축해제 실시 !! -> ml>extend 파일에 같이 넣어둔다 ]
        > unzip ml-100k.zip


14. docker
    - 오픈소스 라이브러리 중에는 윈도우에서 설치가 안되는 유형이 제법 존재한다
    - 보편적으로 리눅스에서는 모두 작동하므로, 도커를 이용하여 리눅스 이미지를 구축하고
      우분트[18.04(late)] 기반에서 환경을 구축하고, fastFM(인수분해머신기능 지원)를 컴파일(OS에 적합하게 -> *.o 생성) 후 설치를 진행한다
      (openCV할때도 같은 과정을 거친다)
    - 이렇게 구축된 추천시스템 라이브러리가 적용된 우분트 이미지를 도커허브에 올려서, 어떤 PC던지 재구축시 빠르게 구성할 수 있다
    - 향후 딥러닝 머신을 사용시 도커를 이용하여 구축하여, 각기 자유롭게 사용이 가능하고, 하둡 클러스터의 시스템 베이스로 사용 가능하다
        (하둡클러스트를 하기 위해서는 스컬러 등의 부수적인 것도 알아야한다)
































