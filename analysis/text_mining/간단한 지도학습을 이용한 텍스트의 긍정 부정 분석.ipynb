{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝의 지도학습(변수, 정담)의 한 알고리즘 사용\n",
    "- 나이브 베이즈 분류 \n",
    "- Naive Bayes Classifier\n",
    "- 두 사건을 서로 독립적으로 가정, 각각의 조건부 확률을 계산\n",
    "- 방식\n",
    " > 샘플 문장 제시 => 긍정/부정인지 답안제시\n",
    " > 이것을 통해서 학습(문자를 형태소 분해를 해서 학습용 데이터로 구성)을 진행\n",
    " > 학습후 모델이 생성이 되고, 이를 통해서 한번도 접하지 못한 문장을 받아서 예측!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize, word_tokenize 땡기기\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos : 긍정\n",
    "# neg : 부정\n",
    "# 연습용(학습용) 데이터 : 학습용과 테스트용( 두개의 비율은 75:25 ) \n",
    "train = [ ('i like you','pos'), \n",
    "          ('i hate you','neg'), \n",
    "          ('you like me','neg'), \n",
    "          ('i like her','pos') ] # 관련없는 두개를 묶어서 비교를 해야되서 튜플로 묶어준다\n",
    "\n",
    "# i가 들어가면 긍정인가?라고 해석하기가 쉽지않다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i like you', 'pos')\n",
      "i\n",
      "like\n",
      "you\n",
      "('i hate you', 'neg')\n",
      "i\n",
      "hate\n",
      "you\n",
      "('you like me', 'neg')\n",
      "you\n",
      "like\n",
      "me\n",
      "('i like her', 'pos')\n",
      "i\n",
      "like\n",
      "her\n"
     ]
    }
   ],
   "source": [
    "for sentence in train:\n",
    "    print(sentence)\n",
    "    # word_tokenize() => 한글의 형태소 분해 과정 유사\n",
    "    for word in word_tokenize(sentence[0]): # 영어 형태소 분석은 : word_tokenize\n",
    "        # 알파벳은 대문자 혹은 소문자로 일치시킨다\n",
    "        print( word.lower() ) # lower(): 소문자로 일치시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'her', 'you', 'like', 'hate']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체문장에서 형태소를 분해하여 중복을 제거하여 리스트로 담아라 한줄로\n",
    "# all_words = \n",
    "all_words = list( set( [word.lower()\n",
    "                     for sentence in train\n",
    "                     for word in word_tokenize(sentence[0])] ) )\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos {'i': True, 'me': False, 'her': False, 'you': True, 'like': True, 'hate': False}\n",
      "neg {'i': True, 'me': False, 'her': False, 'you': True, 'like': False, 'hate': True}\n",
      "neg {'i': False, 'me': True, 'her': False, 'you': True, 'like': True, 'hate': False}\n",
      "pos {'i': True, 'me': False, 'her': True, 'you': False, 'like': True, 'hate': False}\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 텍스트 문장에 all_words에 내용을 대비하여 해당 말뭉치가 있는지 없는지 체킹\n",
    "for x in train:\n",
    "    print( x[1], { word:( word in word_tokenize(x[0]) ) for word in all_words } ) # 말뭉치에서 word를 하나씩 뽑아내고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'i': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'you': True,\n",
       "   'like': True,\n",
       "   'hate': False},\n",
       "  'pos'),\n",
       " ({'i': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'you': True,\n",
       "   'like': False,\n",
       "   'hate': True},\n",
       "  'neg'),\n",
       " ({'i': False,\n",
       "   'me': True,\n",
       "   'her': False,\n",
       "   'you': True,\n",
       "   'like': True,\n",
       "   'hate': False},\n",
       "  'neg'),\n",
       " ({'i': True,\n",
       "   'me': False,\n",
       "   'her': True,\n",
       "   'you': False,\n",
       "   'like': True,\n",
       "   'hate': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전형적인 리스트 내포\n",
    "t = [ ( { word:( word in word_tokenize(x[0]) ) for word in all_words }, x[1] ) \n",
    "      for x in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t를 가지고 학습을 진행하겠다, (이전 단계까지는 재료를 준비하는 과정이었다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "# 알고리즘 생성 및 학습을 한번에 진행\n",
    "classifier = nltk.NaiveBayesClassifier.train( t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()\n",
    "# 학습 결과, 분류의 결과치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 단어 \n",
    "text_sentence = 'i like MeRui' # 말뭉치에 대해서 MeRui는 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': True,\n",
       " 'me': False,\n",
       " 'her': False,\n",
       " 'you': False,\n",
       " 'like': True,\n",
       " 'hate': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이(위의) 문장에 위의 표현처럼 구성( 예측에 관해서 위의 소스코드 출력처럼 구성 ) => {}\n",
    "text_sentence_feature =  { word.lower(): ( word in word_tokenize(text_sentence) ) \n",
    "                           for word in all_words }\n",
    "text_sentence_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 \n",
    "classifier.classify( text_sentence_feature ) # 정확도는 포함안되었다(머신러닝의 맛보기라서 나머지 추가되는 기능은 나중에 배운다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터\n",
    "train = [('아웃백이 좋아','pos'),\n",
    "         ('애슐리도 좋아','pos'),\n",
    "         ('난 자연당이 싫어','neg'),\n",
    "         ('아웃백은 아주 좋은 식당이야','pos'),\n",
    "         ('난 수업 마치고 아웃백에 갈거야','pos')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'갈거야',\n",
       " '난',\n",
       " '마치고',\n",
       " '수업',\n",
       " '식당이야',\n",
       " '싫어',\n",
       " '아웃백에',\n",
       " '아웃백은',\n",
       " '아웃백이',\n",
       " '아주',\n",
       " '애슐리도',\n",
       " '자연당이',\n",
       " '좋아',\n",
       " '좋은'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치를 준비(사전 준비)\n",
    "# 중복제거,\n",
    "# nltk의 토큰나이저 사용시 공백기준으로 명사품사등을 쪼개지 않고 그대로 워드화 하였다\n",
    "all_words = set(  word for sentence in train \n",
    "                  for word in word_tokenize( sentence[0] ) )\n",
    "all_words\n",
    "# 명사와 품사가 같이 나옴, 쪼갤때 공백을 기준으로 쪼갬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'아웃백이': True,\n",
       "   '난': False,\n",
       "   '아웃백에': False,\n",
       "   '아웃백은': False,\n",
       "   '수업': False,\n",
       "   '마치고': False,\n",
       "   '갈거야': False,\n",
       "   '좋아': True,\n",
       "   '자연당이': False,\n",
       "   '아주': False,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '애슐리도': False,\n",
       "   '싫어': False},\n",
       "  'pos'),\n",
       " ({'아웃백이': False,\n",
       "   '난': False,\n",
       "   '아웃백에': False,\n",
       "   '아웃백은': False,\n",
       "   '수업': False,\n",
       "   '마치고': False,\n",
       "   '갈거야': False,\n",
       "   '좋아': True,\n",
       "   '자연당이': False,\n",
       "   '아주': False,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '애슐리도': True,\n",
       "   '싫어': False},\n",
       "  'pos'),\n",
       " ({'아웃백이': False,\n",
       "   '난': True,\n",
       "   '아웃백에': False,\n",
       "   '아웃백은': False,\n",
       "   '수업': False,\n",
       "   '마치고': False,\n",
       "   '갈거야': False,\n",
       "   '좋아': False,\n",
       "   '자연당이': True,\n",
       "   '아주': False,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '애슐리도': False,\n",
       "   '싫어': True},\n",
       "  'neg'),\n",
       " ({'아웃백이': False,\n",
       "   '난': False,\n",
       "   '아웃백에': False,\n",
       "   '아웃백은': True,\n",
       "   '수업': False,\n",
       "   '마치고': False,\n",
       "   '갈거야': False,\n",
       "   '좋아': False,\n",
       "   '자연당이': False,\n",
       "   '아주': True,\n",
       "   '식당이야': True,\n",
       "   '좋은': True,\n",
       "   '애슐리도': False,\n",
       "   '싫어': False},\n",
       "  'pos'),\n",
       " ({'아웃백이': False,\n",
       "   '난': True,\n",
       "   '아웃백에': True,\n",
       "   '아웃백은': False,\n",
       "   '수업': True,\n",
       "   '마치고': True,\n",
       "   '갈거야': True,\n",
       "   '좋아': False,\n",
       "   '자연당이': False,\n",
       "   '아주': False,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '애슐리도': False,\n",
       "   '싫어': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [ ( { word:( word in word_tokenize(x[0]) ) for word in all_words }, x[1] ) \n",
    "      for x in train]\n",
    "t # 긍정상황과 부정상황이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "classifier = nltk.NaiveBayesClassifier.train( t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                      좋은 = False             neg : pos    =      1.1 : 1.0\n",
      "                    아웃백이 = False             neg : pos    =      1.1 : 1.0\n",
      "                      아주 = False             neg : pos    =      1.1 : 1.0\n",
      "                     갈거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                    식당이야 = False             neg : pos    =      1.1 : 1.0\n",
      "                      수업 = False             neg : pos    =      1.1 : 1.0\n",
      "                    아웃백에 = False             neg : pos    =      1.1 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features() # 정확성이 많이 떨어지는 자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 문장\n",
    "test_sentence = '난 수업을 마치고 자연당에 갈거야'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아웃백이 좋아', 'pos'),\n",
       " ('애슐리도 좋아', 'pos'),\n",
       " ('난 자연당이 싫어', 'neg'),\n",
       " ('아웃백은 아주 좋은 식당이야', 'pos'),\n",
       " ('난 수업 마치고 아웃백에 갈거야', 'pos')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'아웃백이': False,\n",
       " '난': False,\n",
       " '아웃백에': False,\n",
       " '아웃백은': False,\n",
       " '수업': False,\n",
       " '마치고': False,\n",
       " '갈거야': False,\n",
       " '좋아': False,\n",
       " '자연당이': False,\n",
       " '아주': False,\n",
       " '식당이야': False,\n",
       " '좋은': False,\n",
       " '애슐리도': False,\n",
       " '싫어': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측할 문장의 데이터화\n",
    "text_sentence_feature =  { word.lower(): ( word in word_tokenize(text_sentence) ) \n",
    "                           for word in all_words }\n",
    "text_sentence_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "classifier.classify( text_sentence_feature ) # 잘못나온 결과(결과는 긍정인데 위에서의 자연당은 부정으로 학습을 해두었기 때문이다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 방식으로 진행을 해보면, 훈련에 필요한 다량의 데이터(문장, 상황) 필요하다\n",
    "# 훈련량이 적거나, 데이터가 적거나, 부정확하다 => 정확도가 떨어진다\n",
    "# 절차적인것만 체크, 한계적인 상황도 고려\n",
    "# 지도학습은 정답을 알고 있어야 한다. 다양하게 구성할 수 있는 문장에 대한 판단이\n",
    "# 쉽지않다. => 많은 문장과 문서중에서 유사한 문자를 찾아내고 =>\n",
    "# 문장을 백터로 표현하여, 백터간의 거리를 구하여 해결 =-> 문장의 유사도\n",
    "# 중점( 백터화하고, 거리를 구하는 것이 중점 포인트다 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1은 임시값 -> 이값들은 향후 하이퍼 파라미터 튜딩이라는 주제에서 값을 다변화하여\n",
    "# 조합 테스트를 수행\n",
    "vectorizer = CountVectorizer( min_df=1 ) # 생성자(): 에서 나오는 함수:하이퍼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 많은 문장을 훈련시켜야 한다. 몇가지 샘플로 진행\n",
    "contents = ['성건이랑 술마시고 싶지만 바쁜데 어떡하죠?',\n",
    "            '성건이는 공원에서 산책하고 노는 것을 싫어해요',\n",
    "            '성건이는 공원에서 노는 것도 싫어해요. 이상해요.',\n",
    "            '먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못하고 있어요.'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform( contents )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, ['것도', '것을', '곳으로', '공원에서', '그러질'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature : 특징들 => 변수\n",
    "len(tmp), tmp[:5]  # 이는, 이랑 등은 다른 단어로 인식하고 있다 (일단 그렇게 알고 있어라)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 4), array([[0, 0, 1, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 1, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1]], dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 feature에 대한 백터값\n",
    "trans = X.toarray().transpose()\n",
    "trans.shape, trans # 자료는 22개이고, 문장은 4개이다.\n",
    "# '것도'라는 feature는 \n",
    "# 훈련용 전체문장 4개중 3번째에 등장한다\n",
    "# 그래서 0,0,1,0 이라는 백턱값을 가지게 된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_features = X.shape # 문장 4개 텍스트 22개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장이 4개\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 4개에서 추출한 말뭉치 22개\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 문장\n",
    "new_post = ['성건이랑 공원에서 산책하고 놀고 싶어요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 백터화 시켜야한다\n",
    "new_post_vec = vectorizer.transform( new_post )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장의 백터화 \n",
    "tmp # 문장 하나에 대한 2진 데이터가 완성됨( 문장의 수치화 ), 딕셔너리가 필요했다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 판단을 하기 위해서 거리 계산( 샘플들의 )\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 계산\n",
    "def dis_raw( v1, v2 ):\n",
    "    delta = v1 - v2\n",
    "    return sp.linalg.norm( delta.toarray() ) # 두개를 빼고 투어레이 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 문장을 반복하면서 이 문장과, 일일이 비교 -> 그 중에 거리가 가장 짧은 문장이 선택된다\n",
    "# 그 문장이 가장 유사한 문장이다 \n",
    "best_distance = 1000 # 임의값\n",
    "best_index = None\n",
    "for i in range( num_samples ): # 샘플 문장수는 4개다\n",
    "    # 각 문장의 백터정보를 리턴\n",
    "    post_vec = X.getrow( i )\n",
    "    # 비교 문장 : new_post_vec\n",
    "    # 거리계산\n",
    "    d = dis_raw( post_vec, new_post_vec )\n",
    "    #print( \"%d %f\" % (i, d) ): 잠시 막아둠  # 출력값은 두번째가 가장 가깝다\n",
    "    # 거리가, best_distance보다 작으면 세팅 \n",
    "    if d < best_distance:\n",
    "        best_distance = d\n",
    "        best_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최소거리 :\n",
    "best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그때의 인덱스\n",
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'성건이는 공원에서 산책하고 노는 것을 싫어해요'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그때의 문장은\n",
    "contents[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'성건이는 공원에서 산책하고 놀고 싶어요'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'성건이는 공원에서 산책하고 놀고 싶어요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> nltk의 말뭉치는 한글과 딱히 맞지가 않다\n",
    "# 한글 전용 형태소 분석기를 활용하여 보다 정확하고, 의미있게 작업을 진행 목표로 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
